{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13fcb2a0",
   "metadata": {},
   "source": [
    "In [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3fc7206",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ROUNDS = 400\n",
    "OPTIMIZE_ROUNDS = False\n",
    "LEARNING_RATE = 0.07\n",
    "EARLY_STOPPING_ROUNDS = 50  \n",
    "\n",
    "# 나는 스스로 판단할 수 있는 많은 정보를 얻기 위해 EARLY_STOPPING_ROUNDS를 높게 설정합니다.(OPTIMIZE_ROUNDS가 설정된 경우)\n",
    "# 만약 실제로 조기 종료를 원한다면 EARLY_STOPPING_ROUNDS를 줄여야합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baef2b8f",
   "metadata": {},
   "source": [
    "처음에는 MAX_ROUNDS를 상당히 높게 설정하고 OPTIMIZE_ROUNDS를 사용하여 적당한 라운드 수를 찾는것을 추천합니다.\n",
    "(제 판단에는, 모든 폴드 사이에서 best_ntree_limit의 최댓값에 가깝게 해야합니다. 모델이 적절히 정규화 되었거나\n",
    "verbose=True를 설정하고, 모든 폴드에서 잘 동작하는 라운드 수를 찾기 위한 세부 정보를 본다면 더 높을 수도 있습니다.)\n",
    "그 다음 OPTIMIZE_ROUNDS를 중지하고, MAX_ROUND를 적절한 총 라운드 수로 설정하세요.\n",
    "\n",
    "각 폴드마다 최적의 라운드를 선택하는 \"조기 종료\" 방식은 검증 데이터에 과적합하는 문제가 존재합니다.\n",
    "따라서 테스트 데이터를 예측하기 위한 최적의 모델을 생성하지 못할 수 있고,\n",
    "다른 모델과 스태킹/앙상블을 위해 검증 데이터를 생성하는 경우 앙상블에 너무 많은 weight를 갖게 할 것입니다.\n",
    "또 다른 문제점은(XGBoost의 기본 값은) 가장 좋은 라운드보다 조기 종료가 발생한 라운드(개선되지 않고 정체되있는 라운드)를 사용하는 것입니다.\n",
    "정체되는 구간이 충분히 길다는 가정이 있다면 이것은 과적합 문제를 해결해줍니다. 그러나 지금까지는 도움이 되지 않았습니다.\n",
    "(모든 폴드에 대해 일정한 라운드로 진행한것보다 폴드 당 20라운드 조기 종료를 한 것이 검증 점수가 안좋았다. 그래서 조기 종료는 실제로는 underfit 처럼 보였다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951254e8",
   "metadata": {},
   "source": [
    "In [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9bd4251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numba import jit\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f458d74",
   "metadata": {},
   "source": [
    "In [3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95af7087",
   "metadata": {},
   "source": [
    "def gini(list_of_values):\n",
    "\n",
    "    sorted_list = sorted(list_of_values)\n",
    "    \n",
    "    height, area = 0, 0\n",
    "    \n",
    "    for value in sorted_list:\n",
    "    \n",
    "        height += value\n",
    "        \n",
    "        area += height - value / 2.\n",
    "        \n",
    "    fair_area = height * len(list_of_values) / 2.\n",
    "    \n",
    "    return (fair_area - area) / fair_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5c40b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## gini 계산\n",
    "## 참고한 링크: https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n",
    "\n",
    "@jit\n",
    "def eval_gini(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true) # numba가 이해할 수 있는 형식으로 변환 \n",
    "    y_true = y_true[np.argsort(y_prob)] # y_prob 기준으로 오름차순 정렬\n",
    "    ntrue = 0 \n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true) # y_true의 길이 n\n",
    "    for i in range(n-1, -1, -1): # y_prob가 큰 수 부터\n",
    "        y_i = y_true[i] # y_true의 값을 순서대로 y_i에 저장\n",
    "        ntrue += y_i # y_i의 값을 ntrue라는 변수에 더함\n",
    "        gini += y_i * delta # y_i * delta값을 gini 변수에 더함\n",
    "        delta += 1 - y_i # 1 - y_i값을 delta 값으로 초기화\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue)) # 반복을 통해 나온 ntrue와 gini값을 이용하여 gini 결과를 구함\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d210ad",
   "metadata": {},
   "source": [
    "In [4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e98a17",
   "metadata": {},
   "source": [
    "머신 러닝 모델을 평가하는 데 사용하기 위해 label과 prediction을 입력으로 받고 계산된 계수를 리턴한다.\n",
    "\n",
    "label을 정렬한 prediction의 인덱스로 재배열했을 때의 지니계수를 구하고, 그 값을 실제값의 지니계수 값으로 나눈 normalized gini coefficient를 사용한다.\n",
    "\n",
    "예측값으로 정렬하여 계산한 지니계수와 원본값의 지니계수를 비교하는 것으로 동일할 경우 1.0을 리턴한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d1c05a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수는 olivier 커널에서 가져왔습니다.\n",
    "# https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283\n",
    "\n",
    "# 원본과 prediction의 누적값이 동일할 때의 1.0의 값이 가장 크므로, loss로 사용하기 위해 음수로 변경해서 일치시 가장 작은 값을 갖게 한다.\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label() # 범례를 추출하여 labels에 저장\n",
    "    gini_score = -eval_gini(labels, preds) # eval_gini 함수를 구해서 -를 붙인 뒤 gini_score에 저장\n",
    "    return [('gini', gini_score)] # gini_score return\n",
    "\n",
    "# series의 길이와 noise_level을 이용하여 noise를 추가해주는 add_noise 함수 정의\n",
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series))) # 노이즈 추가\n",
    "  \n",
    "def target_encode(trn_series=None, # 범주형 train 피처\n",
    "                  val_series=None, # 범주형 \n",
    "                  tst_series=None, # 범주형 test 피처\n",
    "                  target=None, # 타겟 피처\n",
    "                  min_samples_leaf=1, # \n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    \"\"\"\n",
    "    Smoothing은 Daniele Micci-Barreca의 논문에서와 같이 계산됩니다.\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    trn_series : pd.Series 형태의 학습할 범주형 피처\n",
    "    tst_series : pd.Series 형태의 테스트할 범주형 피처\n",
    "    target : pd.Series 형태의 타겟 데이터\n",
    "    min_samples_leaf (int) : 범주의 평균을 고려할 최소 샘플\n",
    "    smoothing (int) : 범주 평균과 이전의 균형을 맞추기 위한 스무딩 효과 \n",
    "    \"\"\" \n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1) # train series와 target을 concat하여 temp에 저장\n",
    "    # Compute target mean\n",
    "    # trn_series의 name 피처를 groupby한 것에서 target의 name피처의 평균과 count값 구함\n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    # Compute smoothing\n",
    "    #\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    # averages에서 mean이랑 count는 drop\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    ft_val_series = pd.merge(\n",
    "        val_series.to_frame(val_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=val_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_val_series.index = val_series.index\n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_val_series, noise_level), add_noise(ft_tst_series, noise_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cff3c4",
   "metadata": {},
   "source": [
    "In [5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56acc390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "train_df = pd.read_csv('./input/train.csv', na_values=\"-1\") # na_values에 들어있는 값들은 csv파일을 불러올 때 자동으로 nan값으로 변경된다.\n",
    "test_df = pd.read_csv('./input/test.csv', na_values=\"-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b4988",
   "metadata": {},
   "source": [
    "In [6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331ec281",
   "metadata": {},
   "source": [
    "feature selection (Boruta 알고리즘)을 하였을 때, shadow feature 보다 feature importance가 높은 경우만 train_features에 저장.\n",
    "\n",
    "이외의 feature는 상대적으로 관련 없을 거라고 판단되어 drop 시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8f69774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# olivier 커널 참고\n",
    "train_features = [\n",
    "    \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n",
    "\t\"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n",
    "\t\"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n",
    "\t\"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n",
    "\t\"ps_ind_15\",  #            :  922.18 / shadow  242.00\n",
    "\t\"ps_reg_02\",  #            :  920.65 / shadow  267.50\n",
    "\t\"ps_car_14\",  #            :  798.48 / shadow  549.58\n",
    "\t\"ps_car_12\",  #            :  731.93 / shadow  293.62\n",
    "\t\"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n",
    "\t\"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n",
    "\t\"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n",
    "\t\"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n",
    "\t\"ps_reg_01\",  #            :  598.60 / shadow  178.57\n",
    "\t\"ps_car_15\",  #            :  593.35 / shadow  226.43\n",
    "\t\"ps_ind_01\",  #            :  547.32 / shadow  154.58\n",
    "\t\"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n",
    "\t\"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n",
    "\t\"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n",
    "\t\"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n",
    "\t\"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n",
    "\t\"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n",
    "\t\"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n",
    "\t\"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n",
    "\t\"ps_car_11\",  #            :  173.28 / shadow   76.45\n",
    "\t\"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n",
    "\t\"ps_calc_09\",  #           :  169.13 / shadow  129.72\n",
    "\t\"ps_calc_05\",  #           :  148.83 / shadow  120.68\n",
    "\t\"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n",
    "\t\"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n",
    "\t\"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n",
    "\t\"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n",
    "\t\"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n",
    "\t\"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n",
    "\t\"ps_ind_14\",  #            :   37.37 / shadow   16.65\n",
    "]\n",
    "# 조합 추가\n",
    "combs = [\n",
    "    ('ps_reg_01', 'ps_car_02_cat'),  \n",
    "    ('ps_reg_01', 'ps_car_04_cat'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354c6ca3",
   "metadata": {},
   "source": [
    "In [7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b199cc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current feature                                 ps_reg_01_plus_ps_car_04_cat    2 in   0.0"
     ]
    }
   ],
   "source": [
    "# 데이터 처리\n",
    "id_test = test_df['id'].values # test DF의 id 피처의 값을 id_test라는 변수에 저장\n",
    "id_train = train_df['id'].values # train DF의 id 피처의 값을 id_train라는 변수에 저장\n",
    "y = train_df['target'] # train DF의 target 피처의 값을 y에 저장\n",
    "\n",
    "start = time.time() # 시작 시간 측정\n",
    "for n_c, (f1, f2) in enumerate(combs): # combs를 enumerate 하여 n_c (인덱스 번호) 반복\n",
    "    name1 = f1 + \"_plus_\" + f2 # 피처 두 개의 이름을 plus 붙여서 합침\n",
    "    print('current feature %60s %4d in %5.1f'\n",
    "          % (name1, n_c + 1, (time.time() - start) / 60), end='') # current feature : 피처 이름, index, 걸린 시간\n",
    "    print('\\r' * 75, end='')\n",
    "    train_df[name1] = train_df[f1].apply(lambda x: str(x)) + \"_\" + train_df[f2].apply(lambda x: str(x)) # 두 피처의 값을 더해서 새로운 피처 생성. train DF에 저장\n",
    "    test_df[name1] = test_df[f1].apply(lambda x: str(x)) + \"_\" + test_df[f2].apply(lambda x: str(x)) # 두 피처의 값을 더해서 새로운 피처 생성. test DF에 저장\n",
    "    # Label Encode (문자열 값을 숫자형 카테고리 값으로 변환)\n",
    "    lbl = LabelEncoder() # p.119 LabelEncoder 객체 생성\n",
    "    lbl.fit(list(train_df[name1].values) + list(test_df[name1].values)) # fit과 transform으로 레이블 인코딩 수행\n",
    "    train_df[name1] = lbl.transform(list(train_df[name1].values))\n",
    "    test_df[name1] = lbl.transform(list(test_df[name1].values))\n",
    "\n",
    "    train_features.append(name1) # train_features에 해당 피처들 저장\n",
    "    \n",
    "X = train_df[train_features] # 전체 train DF에서 해당 피처 값들만 X에 저장\n",
    "test_df = test_df[train_features] # 전체 test DF에서 해당 피처 값들만 test_df에 저장\n",
    "\n",
    "f_cats = [f for f in X.columns if \"_cat\" in f] # cat(범주형) 변수들만 f_cats에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c7bc45",
   "metadata": {},
   "source": [
    "In [8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3c19a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred = 0*y #  y에 저장한 train DF의 target 피처의 값에 0을 곱해 (0으로 만들어) y_valid_pred에 저장\n",
    "y_test_pred = 0 # y_test_pred를 0으로 초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5b068e",
   "metadata": {},
   "source": [
    "In [9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "077c14be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴드 설정 p.103 (교차 검증)\n",
    "K = 5 # K값 5로 설정. 5개의 폴드 세트 즉. 5개의 예측 평가 구할 예정 (5등분)\n",
    "kf = KFold(n_splits = K, random_state = 1, shuffle = True) # n_splits값을 5로 설정하여 KFold 객체 생성\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27a5f0f",
   "metadata": {},
   "source": [
    "In [10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b382534",
   "metadata": {},
   "source": [
    "n_estimators : 반복 수행하려는 트리의 개수\n",
    "\n",
    "max_depth : 트리 최대 깊이\n",
    "\n",
    "objective : 최솟값을 가져야할 손실함수를 정의 (이중분류/다중분류)\n",
    "\n",
    "learning_rate : 부스팅 스텝을 반복적으로 수행할 때 업데이트되는 학습률 값\n",
    "\n",
    "subsample : 트리가 커져서 과적합되는 것을 제어하기 위해 데이터를 샘플링하는 비율을 지정\n",
    "\n",
    "min_child_weight : 트리에서 추가적으로 가지를 나눌지를 결정하기 위해 필요한 데이터들의 weight 총합\n",
    "\n",
    "colsample_bytree : max_features와 유사. 트리 생성에 필요한 피처를 임의로 샘플링 하는데 사용\n",
    "\n",
    "scale_pos_weight : 특정 값으로 치우친 비대칭한 클래스로 구성된 데이터 세트의 균형을 유지하기 위한 파라미터\n",
    "\n",
    "gamma : 트리의 리프 노드를 추가적으로 나눌지를 결정할 최소 손실 감소\n",
    "\n",
    "reg_alpha : L1 regulation 제어를 위한 값 과적합 제어를 위한 것\n",
    "\n",
    "reg_lambda : L2 regulation 제어를 위한 값 과적합 제어를 위한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e7d8e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 분류기 설정\n",
    "model = XGBClassifier(    \n",
    "                        n_estimators=MAX_ROUNDS,\n",
    "                        max_depth=4,\n",
    "                        objective=\"binary:logistic\", # 이진분류\n",
    "                        learning_rate=LEARNING_RATE, \n",
    "                        subsample=.8,\n",
    "                        min_child_weight=6,\n",
    "                        colsample_bytree=.8,\n",
    "                        scale_pos_weight=1.6,\n",
    "                        gamma=10,\n",
    "                        reg_alpha=8,\n",
    "                        reg_lambda=1.3,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1890401",
   "metadata": {},
   "source": [
    "In [11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3098d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:58:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_15112/3932066299.py:4: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"eval_gini\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_15112/3932066299.py (6)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_15112\\3932066299.py\", line 6:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_15112/3932066299.py:4: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"eval_gini\" failed type inference due to: \u001b[1m\u001b[1mCannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_15112\\3932066299.py\", line 12:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit\n",
      "c:\\users\\user\\miniconda3\\lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"eval_gini\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_15112\\3932066299.py\", line 6:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "c:\\users\\user\\miniconda3\\lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_15112\\3932066299.py\", line 6:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Gini =  0.2851059728784705\n",
      "\n",
      "Fold  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:59:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  Gini =  0.28185495483845957\n",
      "\n",
      "Fold  2\n",
      "[15:00:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  Gini =  0.27429910138514\n",
      "\n",
      "Fold  3\n",
      "[15:01:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  Gini =  0.2991202920581566\n",
      "\n",
      "Fold  4\n",
      "[15:01:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  Gini =  0.2857903122299573\n",
      "\n",
      "Gini for full training set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_15112/3932066299.py:4: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"eval_gini\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_15112/3932066299.py (6)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_15112\\3932066299.py\", line 6:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_15112/3932066299.py:4: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"eval_gini\" failed type inference due to: \u001b[1m\u001b[1mCannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_15112\\3932066299.py\", line 12:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit\n",
      "c:\\users\\user\\miniconda3\\lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"eval_gini\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_15112\\3932066299.py\", line 6:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "c:\\users\\user\\miniconda3\\lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_15112\\3932066299.py\", line 6:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.28501477642381845"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CV 실행\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_df)): # 만들어 두었던 kfold 객체로 train DF을 쪼개고 하나씩 실행\n",
    "    \n",
    "    # 폴드에 대한 데이터 생성\n",
    "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index] # train_index와 text_index를 기준으로 y_train과 y_valid로 나눔\n",
    "    X_train, X_valid = X.iloc[train_index,:].copy(), X.iloc[test_index,:].copy() # train_index와 test_index를 기준으로 X를 X_train, X_valid로 나눔\n",
    "    X_test = test_df.copy() # X_test에는 test DF 전체\n",
    "    print( \"\\nFold \", i)\n",
    "    \n",
    "    # 데이터 인코드\n",
    "    for f in f_cats: # 넣어놓았던 범주형 피처 하나씩 반복 (타겟 인코딩 실행)\n",
    "        X_train[f + \"_avg\"], X_valid[f + \"_avg\"], X_test[f + \"_avg\"] = target_encode(\n",
    "                                                        trn_series=X_train[f],\n",
    "                                                        val_series=X_valid[f],\n",
    "                                                        tst_series=X_test[f],\n",
    "                                                        target=y_train,\n",
    "                                                        min_samples_leaf=200,\n",
    "                                                        smoothing=10,\n",
    "                                                        noise_level=0\n",
    "                                                        )\n",
    "    # 폴드에 대한 모델 실행\n",
    "    if OPTIMIZE_ROUNDS:\n",
    "        eval_set=[(X_valid,y_valid)]\n",
    "        fit_model = model.fit( X_train, y_train, \n",
    "                               eval_set=eval_set,\n",
    "                               eval_metric=gini_xgb,\n",
    "                               early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "                               verbose=False\n",
    "                             )\n",
    "        print( \"  Best N trees = \", model.best_ntree_limit ) # 최적의 ntree_limit과 \n",
    "        print( \"  Best gini = \", model.best_score ) # 최적의 지니계수 출력\n",
    "    else:\n",
    "        fit_model = model.fit( X_train, y_train )\n",
    "        \n",
    "    # 폴드에 대한 검증 예측 생성\n",
    "    pred = fit_model.predict_proba(X_valid)[:,1] # 실제 예측값\n",
    "    print( \"  Gini = \", eval_gini(y_valid, pred) ) # 결과값과 실제 예측값 비교\n",
    "    y_valid_pred.iloc[test_index] = pred # 실제 예측값을 test_index에 맞게 y_valid_pred에 저장\n",
    "    \n",
    "    # 테스트 세트의 예측을 누적\n",
    "    y_test_pred += fit_model.predict_proba(X_test)[:,1] # y_test_pred에는 그 에측값을 누적시킴\n",
    "    \n",
    "    del X_test, X_train, X_valid, y_train\n",
    "    \n",
    "y_test_pred /= K  # 테스트 세트 예측의 평균\n",
    "\n",
    "print( \"\\nGini for full training set:\" )\n",
    "eval_gini(y, y_valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f8f8f9",
   "metadata": {},
   "source": [
    "In [12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73ba8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스태킹 / 앙상블을위한 검증 예측 저장\n",
    "val = pd.DataFrame() # val이라는 DF 생성\n",
    "val['id'] = id_train # id_train에 저장해둔 id 값들을 새로운 id피처에 저장\n",
    "val['target'] = y_valid_pred.values # y_valid_pred의 값들을 새로운 target 피처에 저장\n",
    "val.to_csv(DATA_PATH + 'xgb_valid.csv', float_format='%.6f', index=False) # csv파일로 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b77a20",
   "metadata": {},
   "source": [
    "In [13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c894d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 제출 파일 생성\n",
    "sub = pd.DataFrame() # sub이라는 DF 생성\n",
    "sub['id'] = id_test # id_test에 저장해둔 id 값들을 새로운 id피처에 저장\n",
    "sub['target'] = y_test_pred # y_test_pred의 값들을 새로운 target 피처에 저장\n",
    "sub.to_csv(DATA_PATH + 'xgb_submit.csv', float_format='%.6f', index=False) # csv파일로 저장"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
